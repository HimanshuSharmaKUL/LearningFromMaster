{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f573b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee530b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "print(f'Length of text: {len(text)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c520956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "print(text[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a1d30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "#before beginning, let us fist see kaun kaunse characters use ho rahe hain\n",
    "chars = set(text) #unique characters choose ho gaye apne aap, unordered\n",
    "chars = sorted(list(set(text))) #list of set -> we get an ordering, an arbitrary ordering tho. Then sorted makes it a particular ordering\n",
    "chars\n",
    "print(''.join(chars))\n",
    "vocab_size = len(chars) #these characters are our vocabulary, we'll make new words etc from these\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a43f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a mapping from characters to integers\n",
    "#tokenize: convert the string of chars to some sequence of integers acc to some method\n",
    "\n",
    "#one schema for tokenizing is creating a simple look-up table\n",
    "stoi = {ch:i for i,ch in enumerate(chars)} #string to integer\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff6ca067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddccd04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 43, 50, 50, 53]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stoi[c] for c in \"Hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8e6036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H', 'e', 'l', 'l', 'o']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[itos[c] for c in [20, 43, 50, 50, 53]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aec9909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53]\n",
      "Hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = lambda s: [stoi[c] for c in s] #Takes in s and then does [..] on s \n",
    "decoder = lambda s: [itos[c] for c in s]\n",
    "enc = encoder('Hello')\n",
    "dec = decoder(enc)\n",
    "print(enc)\n",
    "print(''.join(dec))\n",
    "def decode(x):\n",
    "    return ''.join(decoder(x))\n",
    "\n",
    "decode(encoder('Hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe9e9722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "#Let us encode and tokenize our dataset\n",
    "data = encoder(text)\n",
    "import torch \n",
    "data = torch.tensor(encoder(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff3e2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train adn validation test\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30ced728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We do not feed the whole training data into the neural networks, we work with chunks of the data\n",
    "#we sample random chunks, some maximum length, aka block size\n",
    "#we call this chunks as context window, or block size\n",
    "block_size = 8\n",
    "train_data[:block_size+1] #here are 9 characters, with 8 examples to train on\n",
    "#18 ke bad 47 aata hai\n",
    "#18 & 47 ke bad 56\n",
    "#18,47,56, ke bad 57 etc and so on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58de3348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size] #block size characters\n",
    "y = train_data[1:block_size+1] #next block_size characters, since it is offset by 1\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1] #input is the chars upto and including t\n",
    "    target = y[t] #target is the t-th character in target array y\n",
    "    print(f\"when input is {context} the target: {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d819e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is tensor([24]) the target: 43\n",
      "when input is tensor([24, 43]) the target: 58\n",
      "when input is tensor([24, 43, 58]) the target: 5\n",
      "when input is tensor([24, 43, 58,  5]) the target: 57\n",
      "when input is tensor([24, 43, 58,  5, 57]) the target: 1\n",
      "when input is tensor([24, 43, 58,  5, 57,  1]) the target: 46\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46]) the target: 43\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46, 43]) the target: 39\n",
      "when input is tensor([44]) the target: 53\n",
      "when input is tensor([44, 53]) the target: 56\n",
      "when input is tensor([44, 53, 56]) the target: 1\n",
      "when input is tensor([44, 53, 56,  1]) the target: 58\n",
      "when input is tensor([44, 53, 56,  1, 58]) the target: 46\n",
      "when input is tensor([44, 53, 56,  1, 58, 46]) the target: 39\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39]) the target: 58\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39, 58]) the target: 1\n",
      "when input is tensor([52]) the target: 58\n",
      "when input is tensor([52, 58]) the target: 1\n",
      "when input is tensor([52, 58,  1]) the target: 58\n",
      "when input is tensor([52, 58,  1, 58]) the target: 46\n",
      "when input is tensor([52, 58,  1, 58, 46]) the target: 39\n",
      "when input is tensor([52, 58,  1, 58, 46, 39]) the target: 58\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58]) the target: 1\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58,  1]) the target: 46\n",
      "when input is tensor([25]) the target: 17\n",
      "when input is tensor([25, 17]) the target: 27\n",
      "when input is tensor([25, 17, 27]) the target: 10\n",
      "when input is tensor([25, 17, 27, 10]) the target: 0\n",
      "when input is tensor([25, 17, 27, 10,  0]) the target: 21\n",
      "when input is tensor([25, 17, 27, 10,  0, 21]) the target: 1\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1]) the target: 54\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1, 54]) the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "#creating batches of the data so that the GPUs are busy and GPUs can train them independently\n",
    "batch_size = 4 #number of indepndent sequences to be trained in parallel every fwd and backward passs of the transformer\n",
    "block_size = 8 #what is max context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    #generate a small batch of data of inputs x an y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,)) #smple a Random location in the whole dataset, pure dataset (from 0 to len(data)-blocksize) me se ek random sample lena hai, 'batch_size'=4 jitne random nos.\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) #.stack(list, dim=0 default) - stack them in rows of 4 rows (batch size) x 8 size ka tensor\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "# ix, _, _ = get_batch('train')\n",
    "# [data[i:i+block_size] for i in ix]\n",
    "# [data[i] for i in ix]\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): #batch dimension\n",
    "    for t in range(block_size): #time dimension or block/context window dimention\n",
    "        context = xb[b, :t+1] #b-th batch item lo, us itme ke 0 se t+1 tk block chars lo. Input comes from x array\n",
    "        target = yb[b, t] #bth batch item lo, aur us itme ka sirf tth char lo. Target comes from y\n",
    "        print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "695493a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "#Now we feed the train data to the simplest language model neural network - i.e. bigram model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        #each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) \n",
    "        #we create a token embedding table of vocabsize x vocabsize\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) #(B,T,C)\n",
    "        #when we pass an index, i.e. xb of size 4x8, then \n",
    "        #every single integer of our xb will refer to the embedding table\n",
    "        #and plucks out a row of that embedding table corresponding to its index\n",
    "        #ex: we have \n",
    "        # xb = > torch.Size([4, 8])\n",
    "        # tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
    "        #         [44, 53, 56,  1, 58, 46, 39, 58],\n",
    "        #         [52, 58,  1, 58, 46, 39, 58,  1],\n",
    "        #         [25, 17, 27, 10,  0, 21,  1, 54]])\n",
    "        #so, 24 will pluck out 24th row, \n",
    "        # 43 will pluck out 43rd row and so on\n",
    "        #and then pytorch arranges them into B,T,C - batch, time, channel tensor\n",
    "        #batch = 4, time = 8, channel = 65 (vocab size), C is also the 'classes'. Basically, the classes into which we're classifying\n",
    "        #and we interpret them as logits, ie scores for next character in the sequence\n",
    "        #-ve log liklihood loss aka cross entropy\n",
    "\n",
    "        if targets is None: \n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            # print(B,T,C)\n",
    "            logits = logits.view(B*T, C) #pytorch wants 'C' as 2nd dimension, so we squash/combine the first 2 dims into one dim and make C as 2nd dim\n",
    "            # print(logits.shape)\n",
    "            targets = targets.view(B*T) \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #idx is (B,T) array of the B no. of current context-s (of length T)\n",
    "        #job of generate is to extend the (B,T) to (B, T+1) to (B, T+2) and so on\n",
    "        #i.e. for all rows in a Batch (i.e. B =4) the columns inc from T to T+1, T+1 is then fed back to generate (T+1)+1 = T+2 and this goes on till the number of max_tookens that we want\n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            #Since this is a bigram model, so focus only on the last time step, pluck out the last step as it will give the prediction for next step. Even though we're feeding all the history into the model, only last character is being used. History is not being used in bigram model rn.\n",
    "            logits = logits[:, -1, :] # logits original size: (B,T,C), The last token's logits for each sequence in the batch, .'. becomes (B,C)\n",
    "            #apply softmax to get probablities\n",
    "            probs = F.softmax(logits, dim=-1) #(B,C)\n",
    "            #sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) # (B,1) #For each batch row, we've 1 prediction for what comes next\n",
    "            #append sampled indec to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1) i.e. concatenated along the 1st dim i.e. T, 0th dim is B here i.e. rows\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb) #forward() is called -> forward(self, xb, yb) .'. idx = xb \n",
    "print(logits.shape) #out.shape\n",
    "print(loss) #-log(1/65) ~ 4.17\n",
    "\n",
    "#Let's make a little 1x1 tensor of 0, i.e. a newline character (or space?) and see \n",
    "idx = torch.zeros((1,1), dtype = torch.long) #datatype is int\n",
    "print(decode(m.generate(idx,max_new_tokens=100)[0].tolist())) #generate returns (B, max_token_size) so, just pluck the 0th batch row  -> convert it to python list  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "201a9b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4212486743927\n"
     ]
    }
   ],
   "source": [
    "#Let's now train\n",
    "#let's create a Pytorch optimiser\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "\n",
    "for steps in range(10000):\n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    #evaluate the loss\n",
    "    logits, loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True) #zero the gradients from the previous steps\n",
    "    loss.backward() #getting the gradients for all the parameters\n",
    "    optimizer.step() #using those gradients to update the parameters\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ffd1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a84bbd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KIZ!\n",
      "\n",
      "we?\n",
      "W$d he k\n",
      "MIV;\n",
      "\n",
      "\n",
      "IETyoZY st:\n",
      "\n",
      "\n",
      "Gheay Yatondgrende'TEQUNathinin: ans nd s\n",
      "\n",
      "OREre.\n",
      "Qhour im, sof bn I's temrpe thithattersuravWhefe h antr forgg m walos nt kit mo RLORZ'd IFknyor!\n",
      "Sindis prewhous oodod.\n",
      "wouprebe bll:CUNTHUSt\n",
      "\n",
      "Thleaix;\n",
      "Malesheais whe; lino.\n",
      "ALI;\n",
      "CXdaimboth,\n",
      "batly, tyous w F nig har-\n",
      "ASerin livin ad:\n",
      "GRveitho wond ve ack'\n",
      "3'd gat held inghe beromUCOFFoce ?Y's.\n",
      "Pat fe, healcof\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1), dtype = torch.long),max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d126ae",
   "metadata": {},
   "source": [
    "## The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d99c72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 #batch, time, channels (embedding length)\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53105d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to have some sort of communication among the tokens now\n",
    "#we want to have current token to take in average of feature vectors of previous tokens\n",
    "#We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "#x-bag-of-words, 'bag-of-words' a term people use when they wanna refer to the average of somethings\n",
    "xbow = torch.zeros((B,T,C)) #initialize the average to 0\n",
    "\n",
    "for b in range(B):\n",
    "    # print(b)\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] #(t,C), #everythin in the current batch dimension b, and upto and including t-th dimension i.e. (1,t,C) or (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0) #average along the row (axis = 0), i.e. collapsing the time, so we get (C)\n",
    "        # print(xprev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38aaf2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152],\n",
       "         [ 0.6258,  0.0255],\n",
       "         [ 0.9545,  0.0643],\n",
       "         [ 0.3612,  1.1679],\n",
       "         [-1.3499, -0.5102],\n",
       "         [ 0.2360, -0.2398],\n",
       "         [-0.9211,  1.5433]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931],\n",
       "         [ 1.4870,  0.5910],\n",
       "         [ 0.1260, -1.5627],\n",
       "         [-1.1601, -0.3348],\n",
       "         [ 0.4478, -0.8016],\n",
       "         [ 1.5236,  2.5086]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 1.0101,  0.1215],\n",
       "         [ 0.1584,  1.1340],\n",
       "         [-1.1539, -0.2984],\n",
       "         [-0.5075, -0.9239],\n",
       "         [ 0.5467, -1.4948],\n",
       "         [-1.2057,  0.5718],\n",
       "         [-0.5974, -0.6937]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.3514, -0.2759],\n",
       "         [-1.5108,  2.1048],\n",
       "         [ 2.7630, -1.7465],\n",
       "         [ 1.4516, -1.5103],\n",
       "         [ 0.8212, -0.2115],\n",
       "         [ 0.7789,  1.5333],\n",
       "         [ 1.6097, -0.4032]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b2083b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f28eae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "--\n",
      "b=tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=tensor([[14., 16.],\n",
      "        [14., 16.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "#This was inefficient\n",
    "#Let's use mathematical trick\n",
    "#matrix multiplicaiton\n",
    "\n",
    "#let's use toy example:\n",
    "torch.manual_seed(42)\n",
    "a = torch.ones(3,3)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a@b  #cross or simply matrix multiplicaiton\n",
    "print(f\"a={a}\")\n",
    "print('--')\n",
    "print(f\"b={b}\")\n",
    "print('--')\n",
    "print(f\"c={c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1db609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "#THE TRICK:\n",
    "#Use a triangular matrix to do the 'sliding window' mean\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "#sum along the cols (axis = 1), #kepdim = True, so that o/p dim retains column dim, i.e. o/p dim is [3,1] (had keep dim = False, o/p dim would've been [3]) .\n",
    "#why keep dim=True? 'cause o/p of shape [3,1] on broadcasting can become [3,3], i.e. columns are just copied while broadcasting and then division happens\n",
    "#which is not possible with o/p of shape [3]\n",
    "a = a/torch.sum(a, 1, keepdim=True) \n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a@b  #cross or simply matrix multiplicaiton\n",
    "print(f\"a={a}\")\n",
    "print('--')\n",
    "print(f\"b={b}\")\n",
    "print('--')\n",
    "print(f\"c={c}\")\n",
    "#1st row (with 1,0,0) x 1st col and 2nd col = just 1st row and just 1st row\n",
    "#2nd row (w. 1,1,0) x 1st col and 2nd col = 1st+2nd row and 1st+2nd row\n",
    "#3rd row (w. 1,1,1) x 1st col and 2nd col = 1st+2nd+3rd row and 1st+2nd+3rd row\n",
    "#i.e. the \"sliding window mean\", or \"accumulative sum\" can be easily done using just matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee73af89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 2:\n",
    "#Let's implement this in our accumulating sum/mean \n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei/wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x \n",
    "# (T,T) @ (B,T,C) \n",
    "# pytorch makes it:\n",
    "# (B,T,T) @ (B,T,C)\n",
    "# then we have, (B,T,T) @ (B,T,C) -> (B,T,C)\n",
    "torch.allclose(xbow, xbow2, rtol=1e-5, atol=1e-5)\n",
    "\n",
    "#What is wei? it is nothing but weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53ee9a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9764fa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now, in elementwise softmax, it exponentiates the elements, \n",
    "#then divides the row with the sum of the row\n",
    "#softmax is like normalisation. #wei here is exact same as wei in version2\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1273827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 3:\n",
    "#adding softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1) \n",
    "xbow3 = wei@x\n",
    "torch.allclose(xbow, xbow3, rtol=1e-5, atol=1e-8)\n",
    "\n",
    "#why we will use version 3 in self attention:\n",
    "# Weights begin with 0. We can think of this as 'intereaction strength' or 'affinity' \n",
    "#tells us how much the tokens of the past that we wanna aggregate/average out\n",
    "#wei = torch.zeros((T,T))\n",
    "#Then, wei.masked_fill(tril == 0, float('-inf')) line says, tokens from the past, cannot communicate.\n",
    "#we set them to -inf, i.e. we will not aggregate anything from those tokens\n",
    "#then it goes thru softmax, and aggregation \"wei@x\" thru matrix multiplication\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c2ce67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 4: self-attention!\n",
    "from httpx import head\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 #batch, time/contex length, channels(dimension of identity embedding)\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "#the following creates a \"unirofm\" distr affinities/association of a token and token previous it, which then lets us do simple average\n",
    "#but instead of this bland/uninformative averaging, we want an informed probab distribution of the previous tokens, representing affinities!\n",
    "#jump->\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1) \n",
    "out = wei@x\n",
    "\n",
    "#->jump\n",
    "#1. Self-Attention\n",
    "#Now, every single token, at each position, emits 2 vectors: key and query\n",
    "#query: what is the current token looking for\n",
    "#key: what do I contain (content and position)?\n",
    "#now, the way we get affinities bw tokens is: that we simple take a dot product bw keys and queries\n",
    "#My Query dot product with all the keys of all the other tokens. Jiske sath jyada value aayi, uske sath affinity jyada\n",
    "#and this affinity is nothing but wei , or weights\n",
    "\n",
    "#lets see a single head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C,head_size, bias=False) #sans bias, it just performs matrix multiplicaiton (xW') output=xW'\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) #x:(B,T,C), key=nn.Linear(C,16) .'. o/p: B,T,16\n",
    "q = query(x) #x:(B,T,C), key=nn.Linear(C,16) .'.  o/p: B,T,16\n",
    "#abhi every token at each position ne bus apne-apne query and keys bana liye hain, no cmmunicaiton has happened till now\n",
    "#Now, communication will happen ↓\n",
    "wei = q @ k.transpose(-2,-1) #(B,T,16) @ (B,16,T) ---> (B,T,T) #ye TxT hi 'attention scores hain'\n",
    "#then just do the same thing as above\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1) \n",
    "out = wei@x\n",
    "out.shape\n",
    "\n",
    "#2. Self.Attention\n",
    "#Now, we do one more thing: 'value'\n",
    "#We do not aggergate the affinity-scores of previous token i.e. we wont do wei@x now\n",
    "#instead, we aggreate the value vector instead of raw x\n",
    "head_size = 16\n",
    "key = nn.Linear(C,head_size, bias=False) #just a head_size x C matrix #16x32 # 'here's what I (a token) have'\n",
    "query = nn.Linear(C, head_size, bias=False) # head_size x C matrix #16x32    # 'here's what I'm (a token) interested in'\n",
    "value = nn.Linear(C, head_size, bias=False) # head_size x C matrix #16x32    # and, if you find me interesting (affinity score) 'here's what I'll communicate to you'\n",
    "k = key(x) #(4,8,32)x(16,32).T = k:(4,8,16)\n",
    "q = query(x) #(4,8,32)x(16,32).T = q:(4,8,16)\n",
    "\n",
    "wei = q@ k.transpose(-2,-1)\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1) \n",
    "\n",
    "v = value(x) #x:(B,T,C), key=nn.Linear(C,16) .'. o/p: B,T,16 #(4,8,32)x(16,32).T = q:(4,8,16)\n",
    "out = wei @ v #we aggregate v instead of raw x\n",
    "#out = wei @ x  #x is kinda like private information to this token\n",
    "out.shape #(4,8,16)  output is 16 dimentional instead of 32, '.' head_size is 16, based on it, value is 16x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6da1072f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c72f10d",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. These 'nodes' have no idea where they're placed in space. This is why we need to positionally encode tokens. Unlike convolutional layer where there is notion of spatial information.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other. So, in graph analogy, we atually have 4 seprate pools (if batch_size is 4) of 8 nodes (context/time length)\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. The block we have here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bf2ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
    "wei = q @ k.transpose(-2, -1) #* head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "217ba705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0966)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd9557a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9416)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0ac9be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.1036)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e40888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Softmax tries to become like 1-hot vector if the i/p vector has extream-er values\n",
    "#vector with values close to 0 will give a 'diffused' vector like ↓\n",
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ef1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector with extremer values tend to converge to 1-Hot vector\n",
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot\n",
    "#So, ye na ho, that's why we do 'scaled attention'. \" \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size).\"\n",
    "#scaling is used to control the variance at initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12740eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\himan\\miniconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dd276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "    def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "        xmean = x.mean(1, keepdim=True) # batch mean  #axis=0: we normalise the columns (=batch norm), axis=1: we normalise the rows (=layer norm)\n",
    "        xvar = x.var(1, keepdim=True) # batch variance \n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = BatchNorm1d(100)\n",
    "x = torch.randn(32,100) #batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "419cdd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac499e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
